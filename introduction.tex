%!TEX root = chi14grammatical.tex
%What does $X$ do? How is $Y$ described? Most analysts and researchers ask themselves these questions while trying to understand a subject.  So far, the field of information retrieval has tackled this problem indirectly: the analyst enters a search query, and the system returns some results. When the underlying data has structure, queries can be specific and targeted -- and there is now a substantial body of work [cite] on how best to issue structured queries over \emph{structured} data. But what if the ``data" is is text -- medical literature, legal records, interview transcripts? Although text is richly structured by rules of  grammar and narrative, it is rarely treated as such. While there is a lot of work on extracting various kinds of structured information from text, there is little on how to make it easy for users to access and query over it.  As the questions above show, however, structured queries over language can be extremely useful. In grammatical terms, they become ``What are the verbs of which $X$ is the subject?'' ``What are the adjectives that modify $Y$?''
%
%Adapting existing structured-query interfaces to grammatical search is problematic for several reasons. The first is that the structures in language are not explicit, like columns in a table, but are implicit, and have to be extracted computationally. Only in the last decade have computational linguistic technologies become fast and accu rate enough to use in the real world.
%
%The second problem is the lack of programming experience among searchers. Current structured query languages like SPARQL have complex syntaxes that require time and effort to learn. For example, here is a SPARQL query for ``What are all the country capitals in Africa?'':
%\begin{verbatim}
%SELECT ?capital ?country
%WHERE {
%  ?x cityname ?capital ;
%     isCapitalOf ?y .
%  ?y countryname ?country ;
%     isInContinent Africa .
%}
%\end{verbatim}
%Even if we assume that only professional analysts engaging in information-intensive work would want to issue such targeted queries,  programming experience is scarce. One study on a query language for selecting phrase structures from sentences found that that only 50\% of the people who wanted to use it had programming experience \cite{}.
%
%The third problem is that there are no common-language terms for grammatical relationships even though ordinary people are perfectly capable of understanding and using them. Modern parsers use standard linguistics terminology to label their outputs, but those technical names and definitions are not always accessible to those outside the field. Take the phrases ``he threw the ball" and ``the ball was thrown by him". In both cases, it is clear that `he' is is the one who `threw' whereas, in grammatical terms, the first phrase is in the active case, and the phrase is in the passive case. The Stanford Dependency Parser \cite{}, for example, outputs two different variants of the verb-subject relation: \code{nsubj(he, threw)} and \code{nsubjpass(he, threw)}. A grammatical search system therefore has to bridge the gap between the relations that are recognizable to people and the relations that are extracted from the data

Web search engines are effective for keyword searches and (increasingly) natural language queries, but intuitive interfaces are still lacking for  syntactically structured queries such as \emph{ find all adjectives that modify ``clothes"}. Such queries are useful in the humanities and social sciences, when scholars are attempting to characterize a concept, and also for developing complex patterns for recognizing entities in text, such as medical terms \cite{hirschman2005overview,maclean2013identifying}, and  products and organizations \cite{culotta2005reducing}.

Our goal is to build interfaces to help humanities scholars search and analyze written literature; however, this group is often skeptical of digital tools, primarily because they are often difficult to use, according to a recent large survey \cite{gibbs_building_2012}.  Another survey found that 50\% of linguists who wished to make very technical  linguistic queries  cannot program \cite{soehn2008requirements}. Despite this, most existing interfaces for structured querying require complex program-like syntax, reducing the likelihood that the target users will be willing or able to use the tool.

To address this gap, we conducted an experiment to investigate how grammatical relationships between English words can be made more recognizable to ordinary people. Following the principle of recognition over recall, as well as the success of auto-suggest in search query interfaces, we hypothesized that examples would help people identify grammatical relationships more accurately than technical names.

Our results confirm that showing examples in the form of words or phrases that match significantly improves the accuracy with which grammatical relationships are recognized. Our findings also showed that different types of relations benefited differently from words and phrases.

These findings suggest that a query interface in which a user enters a word of interest and the system shows candidate grammatical relations augmented with examples from the text will be more successful than the baseline of simply naming the relation and showing gaps where the participating words appear.


%In a follow-up experiment, we found that if distinctive or closed-class words tend to participate in a grammatical relationship, then a list of matching words is the best recognition aid. By contrast, in clausal or long-distance relationships, where the context determines how the two words are related, a list of phrases is best.

%The rest of this paper is structured as follows. In the next section, we summarize the previous work on issuing structured queries over linguistic information extracted from text data. Then, we  describe our experiments and analyze the results. Finally, we summarize our findings and discuss their implications for grammatical search interfaces.
